}
}
}
rm(i,j)
#Storage
theta=matrix(nrow=K,ncol=D)#holds dist of topics over docs
beta=matrix(nrow=K,ncol=V)#holds dist of topics over words
#MCMC Gibbs Sampler
for(i in 1:iters){
for (d in 1:D){
probs=matrix(nrow=V,ncol=K) #holds probs of topic assignments at each step
for(k in 1:K){
for(v in 1:V){
wordDocC=do.call("rbind", lapply(Tcounts0, "[", v, ))[-d,k]
wordCorpusC=matrix(unlist(Tcounts0),nrow=D*V,ncol=K)[,k]
probs[v,k]=((sum(Tcounts0[[d]][-v,k],na.rm=T)+alpha)*(sum(wordDocC,na.rm=T)
+eta))/(sum(wordCorpusC[-seq(v,D*V,by=V)],na.rm=T)+(eta*V))
wordDocC=do.call("rbind", lapply(Tcounts0, "[", v, ))[,k]
beta[k,v]=(eta+sum(wordDocC,na.rm=T))/((V*eta)+sum(wordCorpusC,na.rm=T))
}
theta[k,d]=(alpha+sum(Tcounts0[[d]][,k],na.rm=T))/
((K*alpha)+sum(wordCorpusC,na.rm=T))
}
probs=probs/apply(probs,1,sum)
rm(v,k)
#store new topic assignments
Tassign0[[d]]=cbind(Tassign0[[d]],apply(probs,1,my_sample))
Tassign0[[d]][which(is.na(Tassign0[[d]][,2])),i+2]=NA
#get new counts
for (v in 1:V){
if(is.na(Tassign0[[d]][v,2+i])){Tcounts0[[d]][v,]=NA}
else {
Tcounts0[[d]][v,]=rep(0,K)
Tcounts0[[d]][v,Tassign0[[d]][v,2+i]]=Tassign0[[d]][v,1]
}
}
}
}
final_topics=do.call("rbind",lapply(lapply(Tassign0,t),"[",iters,))
Ddist=lapply(Tassign0,my_sum)
results=list(topicassign=Tassign0,theta=theta,beta=beta,topics=final_topics,
docDist=lapply(Ddist,"/",iters+1))
return(results);
}
test=my_Gibbs(TERMS, K=2, alpha=0.2, eta=0.2, iters=1000)
test$docDist
test$topics
#Examples of mine...
#Functions to clean the code, these are just a first pass and can/should be better
setwd("C:\\Users\\admin-ccook\\Desktop\\Scitor\\RFP\\")
source("Scripts/functions.R")
setwd("C:\\Users\\admin-ccook\\Desktop\\Research\\Data\\")
#Needed libraries
library(tm)
library(topicmodels)
library(lda)
#library(stringr)
library(lsa)
#Create my Corpus of 5 sentences...
new_data=DirSource(directory="Pets2")
corpus=VCorpus(new_data,readerControl=list(reader=readPlain,language='en_CA',load=TRUE))
corpus<-clean.corpus(corpus)
writeCorpus(corpus,"C:\\Users\\admin-ccook\\Desktop")
TERMS=TermDocumentMatrix(corpus)
###My Gibbs fitting and Collapsed Gibbs
my_sample=function(x){
K=length(x)
hold=sample(c(1:K),size=1,prob=x)
return(hold);
}
my_sum<-function(x){
hold=apply(x[,-1],1,my_table,K=2)[-1,]
hold2=hold[,which(hold[1,]+hold[2,]!=0)]
return(hold2);
}
my_table<-function(x,K){
hold=factor(x,levels=c("NA",1:K))
return(table(hold));
}
my_Gibbs<-function(docTerm, #docTerm matrix from the Corpus
K, # of topics
alpha, #
eta, #
iters) #Max number of iterations
{
require("gtools")
#What we know
data=as.matrix(docTerm) #term doc matrix
D=dim(data)[2] # of documents
V=dim(data)[1] # length of vocab
#Storage
Tassign0=list() #holds topic assignments at each step
Tcounts0=list();for(i in 1:D){Tcounts0[[i]]=matrix(0,nrow=V,ncol=K)} #count matrix
#Set initial values such that each document has the same topic and the topics are
#uniformly dist across the documents and get count of topics per document
for(i in 1:D){
Tassign0[[i]]=cbind(data[,i],rep((i%%K+1),length(data[,i])))
Tcounts0[[i]][,(i%%K+1)]=rep(1,length(Tcounts0[[i]][,i%%K+1]))
for (j in 1:V){
if(Tassign0[[i]][j,1]==0) {
Tassign0[[i]][j,2]=NA
Tcounts0[[i]][j,]=NA
}
if(Tassign0[[i]][j,1]>1) {
Tcounts0[[i]][j,(i%%K+1)]=Tassign0[[i]][j,1]
}
}
}
rm(i,j)
#Storage
theta=matrix(nrow=K,ncol=D)#holds dist of topics over docs
beta=matrix(nrow=K,ncol=V)#holds dist of topics over words
#MCMC Gibbs Sampler
for(i in 1:iters){
for (d in 1:D){
probs=matrix(nrow=V,ncol=K) #holds probs of topic assignments at each step
for(k in 1:K){
for(v in 1:V){
wordDocC=do.call("rbind", lapply(Tcounts0, "[", v, ))[-d,k]
wordCorpusC=matrix(unlist(Tcounts0),nrow=D*V,ncol=K)[,k]
probs[v,k]=((sum(Tcounts0[[d]][-v,k],na.rm=T)+alpha)*(sum(wordDocC,na.rm=T)
+eta))/(sum(wordCorpusC[-seq(v,D*V,by=V)],na.rm=T)+(eta*V))
wordDocC=do.call("rbind", lapply(Tcounts0, "[", v, ))[,k]
beta[k,v]=(eta+sum(wordDocC,na.rm=T))/((V*eta)+sum(wordCorpusC,na.rm=T))
}
theta[k,d]=(alpha+sum(Tcounts0[[d]][,k],na.rm=T))/
((K*alpha)+sum(wordCorpusC,na.rm=T))
}
probs=probs/apply(probs,1,sum)
rm(v,k)
#store new topic assignments
Tassign0[[d]]=cbind(Tassign0[[d]],apply(probs,1,my_sample))
Tassign0[[d]][which(is.na(Tassign0[[d]][,2])),i+2]=NA
#get new counts
for (v in 1:V){
if(is.na(Tassign0[[d]][v,2+i])){Tcounts0[[d]][v,]=NA}
else {
Tcounts0[[d]][v,]=rep(0,K)
Tcounts0[[d]][v,Tassign0[[d]][v,2+i]]=Tassign0[[d]][v,1]
}
}
}
}
final_topics=do.call("rbind",lapply(lapply(Tassign0,t),"[",iters,))
Ddist=lapply(Tassign0,my_sum)
results=list(topicassign=Tassign0,theta=theta,beta=beta,topics=final_topics,
docDist=lapply(Ddist,"/",iters+1))
return(results);
}
#####check....
test=my_Gibbs(TERMS, K=2, alpha=0.2, eta=0.2, iters=1000)
test$docDist
test$topics
###My Gibbs fitting and Collapsed Gibbs
my_sample=function(x){
K=length(x)
hold=sample(c(1:K),size=1,prob=x)
return(hold);
}
my_sum<-function(x){
hold=apply(x[,-1],1,my_table,K=2)[-1,]
hold2=hold[,which(hold[1,]+hold[2,]!=0)]
return(hold2);
}
my_table<-function(x,K){
hold=factor(x,levels=c("NA",1:K))
return(table(hold));
}
my_Gibbs<-function(docTerm, #docTerm matrix from the Corpus
K, # of topics
alpha, #
eta, #
iters) #Max number of iterations
{
require("gtools")
#What we know
data=as.matrix(docTerm) #term doc matrix
D=dim(data)[2] # of documents
V=dim(data)[1] # length of vocab
#Storage
Tassign0=list() #holds topic assignments at each step
Tcounts0=list();for(i in 1:D){Tcounts0[[i]]=matrix(0,nrow=V,ncol=K)} #count matrix
#Set initial values such that each document has the same topic and the topics are
#uniformly dist across the documents and get count of topics per document
for(i in 1:D){
Tassign0[[i]]=cbind(data[,i],rep((i%%K+1),length(data[,i])))
Tcounts0[[i]][,(i%%K+1)]=rep(1,length(Tcounts0[[i]][,i%%K+1]))
for (j in 1:V){
if(Tassign0[[i]][j,1]==0) {
Tassign0[[i]][j,2]=NA
Tcounts0[[i]][j,]=NA
}
if(Tassign0[[i]][j,1]>1) {
Tcounts0[[i]][j,(i%%K+1)]=Tassign0[[i]][j,1]
}
}
}
rm(i,j)
#Storage
theta=matrix(nrow=K,ncol=D)#holds dist of topics over docs
beta=matrix(nrow=K,ncol=V)#holds dist of topics over words
#MCMC Gibbs Sampler
for(i in 1:iters){
for (d in 1:D){
probs=matrix(nrow=V,ncol=K) #holds probs of topic assignments at each step
for(k in 1:K){
for(v in 1:V){
wordDocC=do.call("rbind", lapply(Tcounts0, "[", v, ))[-d,k]
wordCorpusC=matrix(unlist(Tcounts0),nrow=D*V,ncol=K)[,k]
probs[v,k]=((sum(Tcounts0[[d]][-v,k],na.rm=T)+alpha)*(sum(wordDocC,na.rm=T)
+eta))/(sum(wordCorpusC[-seq(v,D*V,by=V)],na.rm=T)+(eta*V))
wordDocC=do.call("rbind", lapply(Tcounts0, "[", v, ))[,k]
beta[k,v]=(eta+sum(wordDocC,na.rm=T))/((V*eta)+sum(wordCorpusC,na.rm=T))
}
theta[k,d]=(alpha+sum(Tcounts0[[d]][,k],na.rm=T))/
((K*alpha)+sum(wordCorpusC,na.rm=T))
}
probs=probs/apply(probs,1,sum)
rm(v,k)
#store new topic assignments
Tassign0[[d]]=cbind(Tassign0[[d]],apply(probs,1,my_sample))
Tassign0[[d]][which(is.na(Tassign0[[d]][,2])),i+2]=NA
#get new counts
for (v in 1:V){
if(is.na(Tassign0[[d]][v,2+i])){Tcounts0[[d]][v,]=NA}
else {
Tcounts0[[d]][v,]=rep(0,K)
Tcounts0[[d]][v,Tassign0[[d]][v,2+i]]=Tassign0[[d]][v,1]
}
}
}
}
final_topics=do.call("rbind",lapply(lapply(Tassign0,t),"[",iters,))
Ddist=lapply(Tassign0,my_sum)
results=list(topicassign=Tassign0,theta=theta,beta=beta,topics=final_topics,
docDist=lapply(Ddist,"/",iters+1))
return(results);
}
#####check....
test=my_Gibbs(TERMS, K=2, alpha=0.2, eta=0.2, iters=5000)
test$docDist
test$topics
corpus=TERMS
D=dim(corpus)[2]
V=dim(corpus)[1]
K=2 #Topics should be pets and food
iter=5000
t1=Sys.time()
fit1=LDA(t(corpus),k=K,method="Gibbs",control=
list(seed=2,iter=iter))
t2=Sys.time()
t2-t1
#turn doc term matrix into the correct form for lda pkg
####Preprocess Data
documents=dtm2ldaformat(t(corpus), omit_empty = TRUE)
vocab=Terms(corpus)
t1 <- Sys.time()
fit2=lda.collapsed.gibbs.sampler(documents = documents[[1]], K = K, vocab = vocab,
num.iterations = iter, alpha = 0.4,
eta = 0.4, initial = NULL, burnin = 0,
compute.log.likelihood = FALSE)
t2 <- Sys.time()
t2-t1
##############################################################################################################################################
##############################################################################################################################################
##############################################################################################################################################
#Results
dim(fit2$document_sums)
distribution=fit2$document_sums*(1/apply(fit2$document_sums,2,sum))
distribution
results=my_cos(r=136,ta=4,distribution)
apply(results,2,which.max)
apply(results,2,order)
fit1@wordassignments$i
exp(fit1@beta)
fit1@gamma
fit1@wordassignments[[1]]
fit1@wordassignments[[5]]
fit2$document_sums
fit2
test$topics
setwd("C:/Users/admin-ccook/Desktop/Research")
install.packages("statnet", dependencies = TRUE)
library(statnet)
set.seed(12345)
setwd("C:\\Users\\admin-ccook\\Desktop)
###Unweighted Sociomatrix (adjacency matrix)
num_nodes=10
my_sociomatrix <- matrix(round(runif(num_nodes*num_nodes)), # edge values
nrow = num_nodes, #nrow must be same as ncol
ncol = num_nodes)
num_nodes=10
my_sociomatrix <- matrix(round(runif(num_nodes*num_nodes)), # edge values
nrow = num_nodes, #nrow must be same as ncol
ncol = num_nodes)
diag(my_sociomatrix) <- 0
net <- as.network(x = my_sociomatrix, # the network object
directed = TRUE, # specify whether the network is directed
loops = FALSE, # do we allow self ties (should not allow them)
matrix.type = "adjacency" # the type of input
)
network.vertex.names(net) <- c("Susan","Rachel","Angela","Carly","Stephanie","Tom","Mike","Tony","Matt","Steven")
# Create the variable
gender <- c(rep("Female",num_nodes/2),rep("Male",num_nodes/2))
# Take a look at our variable
print(gender)
# Add it to the network object
set.vertex.attribute(net, # the name of the network object
"Gender", # the name we want to reference the variable by in that object
gender # the value we are giving that variable
)
age <- round(rnorm(num_nodes,20,3))
set.vertex.attribute(net,"Age",age)
summary.network(net, # the network we want to look at
print.adj = FALSE # if TRUE then this will print out the whole
#adjacency matrix.
)
node_colors <- rep("",num_nodes)
for(i in 1:num_nodes){
if(get.node.attr(net,"Gender")[i] == "Female"){
node_colors[i] <- "lightblue"
}else{
node_colors[i] <- "maroon"
}
}
print(node_colors)
pdf("Network_Plot_1.pdf", # name of pdf (need to include .pdf)
width = 10, # width of resulting pdf in inches
height = 10 # height of resulting pdf in inches
)
plot.network(net, # our network object
vertex.col = node_colors, # color nodes by gender
vertex.cex = (age)/5, # size nodes by their age
displaylabels = T, # show the node names
label.pos = 5 # display the names directly over nodes
)
dev.off() # finishes plotting and finalizes pdf
getwd()
num_nodes <- 40
num_edges <- 80
node_names <- rep("",num_nodes)
for(i in 1:num_nodes){
node_names[i] <- paste("person",i,sep = "_")
}
print(node_names)
edgelist <- matrix("",nrow= num_edges,ncol = 2)
for(i in 1:num_edges){
edgelist[i,] <- sample(x= node_names, # the names we want to sample from
size = 2, # sender and receiver
replace = FALSE # we do not allow self edges
)
}
print(edgelist)
net2 <- network.initialize(num_nodes)
network.vertex.names(net2) <- node_names
net2[as.matrix(edgelist)] <- 1
income <- round(rnorm(num_nodes,mean = 50000,sd = 20000))
set.vertex.attribute(net2,"Income",income)
summary.network(net2,print.adj = FALSE)
edge_weights <- round(runif(num_edges,min = 1,max = 5))
set.edge.value(net2,"trust",edge_weights)
adjacency_matrix_2 <- net2[,]
num_nodes <- length(net2$val)
node_colors <- rep("",num_nodes)
maximum <- max(get.node.attr(net2,"Income"))
for(i in 1:num_nodes){
#' Calculate the intensity of the node color depending on the person's
#' relative income.
intensity <- round((get.node.attr(net2,"Income")[i]/maximum)*255)
node_colors[i] <- rgb(red = 51, # the proportion of red
green = 51, # the proportion of green
blue = 153, # the proportion of blue
alpha = intensity, # the intensity of the color
max = 255 # the maximum possible intensity
)
}
pdf("Network_Plot_2.pdf", # name of pdf (need to include .pdf)
width = 20, # width of resulting pdf in inches
height = 20 # height of resulting pdf in inches
)
plot.network(net2,
vertex.col = node_colors, # color nodes by gender
vertex.cex = 3, # set node size to a fixed value
displaylabels = T, # show the node names
label.pos = 5, # display the names directly over nodes
label.col = "yellow", # the color of node lables
edge.lwd = get.edge.value(net2,"trust") # edge width based on trust
)
dev.off() # finishes plotting and finalizes pdf
##############################################################
###Weighted sociomatrix
num_nodes <- 100
edge_values <- round(runif(n = num_nodes*num_nodes , min = 1, max = 100))*round(runif(n = num_nodes*num_nodes, min = 0, max = .51))
my_sociomatrix2 <- matrix(edge_values, nrow = 100, ncol = 100)
diag(my_sociomatrix2) <- 0
net3 <- as.network(x = my_sociomatrix2, # the network object
directed = TRUE, # specify whether the network is directed
loops = FALSE, # do we allow self ties (should not allow them)
matrix.type = "adjacency" # the type of input
)
size <- round(rnorm(num_nodes,100,10))
set.vertex.attribute(net3,"Size",size)
summary.network(net3,print.adj = FALSE)
pdf("Network_Plot_3.pdf", # name of pdf (need to include .pdf)
width = 20, # width of resulting pdf in inches
height = 20 # height of resulting pdf in inches
)
plot.network(net3,
vertex.col = "purple", #just one color
displaylabels = F, # no node names
edge.lwd = log(get.edge.value(net3,"Weight")) # edge width
)
dev.off() # finishes plotting and finalizes pdf
num_nodes <- 100
edge_values <- round(runif(n = num_nodes*num_nodes , min = 1, max = 100))*round(runif(n = num_nodes*num_nodes, min = 0, max = .51))
my_sociomatrix2 <- matrix(edge_values, nrow = 100, ncol = 100)
diag(my_sociomatrix2) <- 0
net3 <- as.network(x = my_sociomatrix2, # the network object
directed = TRUE, # specify whether the network is directed
loops = FALSE, # do we allow self ties (should not allow them)
matrix.type = "adjacency" # the type of input
)
size <- round(rnorm(num_nodes,100,10))
set.vertex.attribute(net3,"Size",size)
summary.network(net3,print.adj = FALSE)
pdf("Network_Plot_3.pdf", # name of pdf (need to include .pdf)
width = 20, # width of resulting pdf in inches
height = 20 # height of resulting pdf in inches
)
plot.network(net3,
vertex.col = "purple", #just one color
displaylabels = F, # no node names
edge.lwd = log(get.edge.value(net3,"Weight")) # edge width
)
log(get.edge.value(net3,"Weight"))
get.edge.value(net3,"Weight")
edge.lwd = log(get.edge.value(net3,"Size")) # edge width
get.edge.value(net3,"Size")
num_nodes <- 100
edge_values <- round(runif(n = num_nodes*num_nodes , min = 1, max = 100))*
round(runif(n = num_nodes*num_nodes, min = 0, max = .51))
my_sociomatrix2 <- matrix(edge_values, nrow = 100, ncol = 100)
diag(my_sociomatrix2) <- 0
net3 <- as.network(x = my_sociomatrix2, # the network object
directed = TRUE, # specify whether the network is directed
loops = FALSE, # do we allow self ties (should not allow them)
matrix.type = "adjacency" # the type of input
)
size <- round(rnorm(num_nodes,100,10))
set.vertex.attribute(net3,"Size",size)
summary.network(net3,print.adj = FALSE)
pdf("Network_Plot_3.pdf", # name of pdf (need to include .pdf)
width = 20, # width of resulting pdf in inches
height = 20 # height of resulting pdf in inches
)
plot.network(net3,
vertex.col = "purple", #just one color
displaylabels = F, # no node names
edge.lwd = log(get.edge.value(net3,"Size")) # edge width
)
get.edge.value(net3,"Size")
summary.network(net3,print.adj = FALSE)
help("get.edge.value")
num_nodes <- 100
edge_values <- round(runif(n = num_nodes*num_nodes , min = 1, max = 100))*
round(runif(n = num_nodes*num_nodes, min = 0, max = .51))
my_sociomatrix2 <- matrix(edge_values, nrow = 100, ncol = 100)
diag(my_sociomatrix2) <- 0
net3 <- as.network(x = my_sociomatrix2, # the network object
directed = TRUE, # specify whether the network is directed
loops = FALSE, # do we allow self ties (should not allow them)
matrix.type = "adjacency" # the type of input
)
size <- round(rnorm(num_nodes,100,10))
set.edge.attribute(net3,"Size",size)
summary.network(net3,print.adj = FALSE)
pdf("Network_Plot_3.pdf", # name of pdf (need to include .pdf)
width = 20, # width of resulting pdf in inches
height = 20 # height of resulting pdf in inches
)
plot.network(net3,
vertex.col = "purple", #just one color
displaylabels = F, # no node names
edge.lwd = log(get.edge.value(net3,"Size")) # edge width
)
dev.off() # finishes plotting and finalizes pdf
dev.off() # finishes plotting and finalizes pdf
##############################################################
dev.off() # finishes plotting and finalizes pdf
num_nodes <- 100
edge_values <- round(runif(n = num_nodes*num_nodes , min = 1, max = 100))*
round(runif(n = num_nodes*num_nodes, min = 0, max = .51))
my_sociomatrix2 <- matrix(edge_values, nrow = 100, ncol = 100)
diag(my_sociomatrix2) <- 0
net3 <- as.network(x = my_sociomatrix2, # the network object
directed = TRUE, # specify whether the network is directed
loops = FALSE, # do we allow self ties (should not allow them)
matrix.type = "adjacency" # the type of input
)
size <- round(rnorm(num_nodes,100,10))
set.edge.attribute(net3,"Size",size)
summary.network(net3,print.adj = FALSE)
pdf("Network_Plot_3.pdf", # name of pdf (need to include .pdf)
width = 20, # width of resulting pdf in inches
height = 20 # height of resulting pdf in inches
)
plot.network(net3,
vertex.col = "purple", #just one color
displaylabels = F, # no node names
edge.lwd = log(get.edge.value(net3,"Size")) # edge width
)
dev.off()
