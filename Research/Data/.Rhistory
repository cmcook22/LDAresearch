#Functions to simulate a Corpus and Get its Word/Doc Distributions
simulateCorpus <- function(K, # Number of Topics
D, # number of documents
N, # Length of Vocab
DocLen=1, #Vector of document lengths
eta, #prior for topics over vocabulary
alpha, #prior for documents over topics
lambda)
{
####Check inputs to model
if(length(eta)!=N){stop("Error: Hyperparameter for Vocab is not correct Dimension"); return;}
#if(sum(eta)!=1){stop("Error: Hyperparameter for Vocab does not sum to 1"); return;}
if(length(alpha)!=K){print("Error: Hyperparameter for Topics is not correct Dimension");return;}
#if(sum(alpha)!=1){stop("Error: Hyperparameter for Topics does not sum to 1");return;}
if(length(DocLen)!=D){print("Warning: Leanth of Documents will be randomly generated from Poisson Distribution")
DocLen=rpois(D,lambda=lambda)
}
#####Draw priors for topic distributions over the vocabulary
require("gtools")
Beta=cbind(rdirichlet(K,eta)) #k rows, N cols
#Storage for final topics and words
documents=list()
tdm=matrix(0,nrow=N,ncol=D)
#####Create each document in the Corpus
for(i in 1:D){
#Draw prior for document distribution over topics
Theta=rdirichlet(1,alpha) # 1 row, 3 columns
#Get the jth word for document i
hold=matrix(nrow=DocLen[i],ncol=2)
colnames(hold)=c("topics","words")
for (j in 1:DocLen[i]){
#Draw the topic for the word
hold[j,1]=which(rmultinom(1,1,Theta)==1)
#Draw the actual word
hold[j,2]=which(rmultinom(1,1,Beta[hold[j,1],])==1)
}
documents[[i]]=hold
tdm[sort(unique(hold[,2])),i]=table(hold[,2])
Word_Topic_Count=matrix(0,nrow=N,ncol=K)
for(v in 1:dim(hold)[1]){
Word_Topic_Count[hold[v,2],hold[v,1]]=Word_Topic_Count[hold[v,2],
hold[v,1]]+1
}
}
results=list(documents=documents,tdm=tdm,word_counts=Word_Topic_Count)
return(results);
}
Doc_Topic_Count<-function(results,K){
#Check results are from simulateCorpus
if(is.list(results)==FALSE){stop("Error: Results must be the results from simulateCorpus"); return;}
D=length(results)
hold=matrix(nrow=D,ncol=K)
#Get topic dist for each doc
for (i in 1:D){
hold[i,]=table(factor(results[[i]][,1],levels=seq(1,K)))
}
return(hold);
}
Word_Topic_Count<-function(results,K){
#Check results are from simulateCorpus
if(is.list(results)==FALSE){stop("Error: Results must be the results from simulateCorpus"); return;}
D=length(results)
hold=matrix(nrow=D,ncol=K)
#Get topic dist for each doc
for (i in 1:D){
hold[i,]=table(factor(results[[i]][,1],levels=seq(1,K)))
}
return(hold);
}
####Testing...
Corpus=simulateCorpus(K=3, # Topics
D=10, # documents
N=100, # Vocab
eta=rep(0.01,100),
alpha=c(0.3,0.3,0.4),lambda=10)
ls(Corpus)
Corpus$word_counts
aapply(apply(Corpus$word_Counts,1,sum),2,sum)
apply(apply(Corpus$word_Counts,1,sum),2,sum)
sum(apply(Corpus$word_Counts,1,sum))
apply(Corpus$word_Counts,1,sum)
apply(Corpus$word_counts,1,sum)
sum(apply(Corpus$word_counts,1,sum))
documents[[10]]
Corpus$documents[[10]]
apply(Corpus$word_counts,2,sum)
#Functions to simulate a Corpus and Get its Word/Doc Distributions
simulateCorpus <- function(K, # Number of Topics
D, # number of documents
N, # Length of Vocab
DocLen=1, #Vector of document lengths
eta, #prior for topics over vocabulary
alpha, #prior for documents over topics
lambda)
{
####Check inputs to model
if(length(eta)!=N){stop("Error: Hyperparameter for Vocab is not correct Dimension"); return;}
#if(sum(eta)!=1){stop("Error: Hyperparameter for Vocab does not sum to 1"); return;}
if(length(alpha)!=K){print("Error: Hyperparameter for Topics is not correct Dimension");return;}
#if(sum(alpha)!=1){stop("Error: Hyperparameter for Topics does not sum to 1");return;}
if(length(DocLen)!=D){print("Warning: Leanth of Documents will be randomly generated from Poisson Distribution")
DocLen=rpois(D,lambda=lambda)
}
#####Draw priors for topic distributions over the vocabulary
require("gtools")
Beta=cbind(rdirichlet(K,eta)) #k rows, N cols
#Storage for final topics and words
documents=list()
tdm=matrix(0,nrow=N,ncol=D)
Word_Topic_Count=matrix(0,nrow=N,ncol=K)
#####Create each document in the Corpus
for(i in 1:D){
#Draw prior for document distribution over topics
Theta=rdirichlet(1,alpha) # 1 row, 3 columns
#Get the jth word for document i
hold=matrix(nrow=DocLen[i],ncol=2)
colnames(hold)=c("topics","words")
for (j in 1:DocLen[i]){
#Draw the topic for the word
hold[j,1]=which(rmultinom(1,1,Theta)==1)
#Draw the actual word
hold[j,2]=which(rmultinom(1,1,Beta[hold[j,1],])==1)
}
documents[[i]]=hold
tdm[sort(unique(hold[,2])),i]=table(hold[,2])
for(v in 1:dim(hold)[1]){
Word_Topic_Count[hold[v,2],hold[v,1]]=Word_Topic_Count[hold[v,2],
hold[v,1]]+1
}
}
results=list(documents=documents,tdm=tdm,word_counts=Word_Topic_Count)
return(results);
}
Doc_Topic_Count<-function(results,K){
#Check results are from simulateCorpus
if(is.list(results)==FALSE){stop("Error: Results must be the results from simulateCorpus"); return;}
D=length(results)
hold=matrix(nrow=D,ncol=K)
#Get topic dist for each doc
for (i in 1:D){
hold[i,]=table(factor(results[[i]][,1],levels=seq(1,K)))
}
return(hold);
}
Word_Topic_Count<-function(results,K){
#Check results are from simulateCorpus
if(is.list(results)==FALSE){stop("Error: Results must be the results from simulateCorpus"); return;}
D=length(results)
hold=matrix(nrow=D,ncol=K)
#Get topic dist for each doc
for (i in 1:D){
hold[i,]=table(factor(results[[i]][,1],levels=seq(1,K)))
}
return(hold);
}
####Testing...
Corpus=simulateCorpus(K=3, # Topics
D=10, # documents
N=100, # Vocab
eta=rep(0.01,100),
alpha=c(0.3,0.3,0.4),lambda=10)
Doc_Topic_Count(Corpus$documents,K=3)
Corpus$word_counts
setwd("C:/Users/admin-ccook/Desktop/Research")
#Functions to simulate a Corpus and Get its Word/Doc Distributions
simulateCorpus <- function(K, # Number of Topics
D, # number of documents
N, # Length of Vocab
DocLen=1, #Vector of document lengths
eta, #prior for topics over vocabulary
alpha, #prior for documents over topics
lambda) #Mean for Pois dist of words per doc
{
####Check inputs to model
if(length(eta)!=N){stop("Error: Hyperparameter for Vocab is not correct Dimension"); return;}
if(length(alpha)!=K){print("Error: Hyperparameter for Topics is not correct Dimension");return;}
if(length(DocLen)==1){print("Warning: Leanth of Documents will be randomly generated from Poisson Distribution")
DocLen=rpois(D,lambda=lambda)
}
#####Draw priors for topic distributions over the vocabulary
require("gtools")
Beta=cbind(rdirichlet(K,eta)) #k rows, N cols
#Storage for final topics and words
documents=list()
tdm=matrix(0,nrow=N,ncol=D)
Word_Topic_Count=matrix(0,nrow=N,ncol=K)
Theta=matrix(nrow=D,ncol=K)
#####Create each document in the Corpus
for(i in 1:D){
#Draw prior for document distribution over topics
Theta[i,]=rdirichlet(1,alpha) # 1 row, 3 columns
#Get the jth word for document i
hold=matrix(nrow=DocLen[i],ncol=2)
colnames(hold)=c("topics","words")
for (j in 1:DocLen[i]){
#Draw the topic for the word
hold[j,1]=which(rmultinom(1,1,Theta[i,])==1)
#Draw the actual word
hold[j,2]=which(rmultinom(1,1,Beta[hold[j,1],])==1)
}
documents[[i]]=hold
tdm[sort(unique(hold[,2])),i]=table(hold[,2])
for(v in 1:dim(hold)[1]){
Word_Topic_Count[hold[v,2],hold[v,1]]=Word_Topic_Count[hold[v,2],
hold[v,1]]+1
}
}
results=list(documents=documents,tdm=tdm,word_counts=Word_Topic_Count,Theta=Theta,
Beta=Beta)
return(results);
}
Doc_Topic_Count<-function(results,K){
#Check results are from simulateCorpus
if(is.list(results)==FALSE){stop("Error: Results must be the results from simulateCorpus"); return;}
D=length(results)
hold=matrix(nrow=D,ncol=K)
#Get topic dist for each doc
for (i in 1:D){
hold[i,]=table(factor(results[[i]][,1],levels=seq(1,K)))
}
return(hold);
}
Corpus=simulateCorpus(K=3, # Topics
D=10, # documents
N=100, # Vocab
eta=rep(0.4,100),
alpha=rep(0.4,3),lambda=10)
ls(Corpus)
corpus$Beta
Corpus$Beta
Corpus$Theta
apply(Corpus$Theta,2,sum)
apply(Corpus$Theta,1,sum)
apply(Corpus$Beta,1,sum)
setwd("C:\\Users\\admin-ccook\\Desktop\\Scitor\\RFP\\")
source("Scripts/functions.R")
setwd("C:\\Users\\admin-ccook\\Desktop\\Research\\Data\\")
#Needed libraries
library(tm)
library(topicmodels)
library(lda)
#library(stringr)
library(lsa)
#Create my Corpus of 5 sentences...
new_data=DirSource(directory="Pets2")
corpus=VCorpus(new_data,readerControl=list(reader=readPlain,language='en_CA',load=TRUE))
corpus<-clean.corpus(corpus)
writeCorpus(corpus,"C:\\Users\\admin-ccook\\Desktop")
TERMS=TermDocumentMatrix(corpus)
#Test out other two algorithms and their results...
corpus=TERMS
D=dim(corpus)[2]
V=dim(corpus)[1]
K=2 #Topics should be pets and food
iter=5000
t1=Sys.time()
fit1=LDA(t(corpus),k=K,method="Gibbs",control=
list(seed=2,iter=iter))
t2=Sys.time()
t2-t1
help("LDA")
